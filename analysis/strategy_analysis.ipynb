{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3445d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4547a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(concepts, messages):\n",
    "    \"\"\"\n",
    "    Measure mutual information between concepts c and messages m (assuming\n",
    "    enumerability)\n",
    "    \"\"\"\n",
    "    # Assign int values\n",
    "    c2i = {}\n",
    "    m2i = {}\n",
    "\n",
    "    for c, m in zip(concepts, messages):\n",
    "        if c not in c2i:\n",
    "            c2i[c] = len(c2i)\n",
    "        if m not in m2i:\n",
    "            m2i[m] = len(m2i)\n",
    "\n",
    "    cis = [c2i[c] for c in concepts]\n",
    "    mis = [m2i[m] for m in messages]\n",
    "\n",
    "    return normalized_mutual_info_score(cis, mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8047eabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perfect-teacher_lang_max-message-len=12_train-percent=0.05_log_train.pkl',\n",
       " 'perfect-teacher_lang_max-message-len=12_train-percent=0.05_log_val.pkl',\n",
       " 'perfect-teacher_lang_max-message-len=12_train-percent=0.8_log_train.pkl',\n",
       " 'perfect-teacher_lang_max-message-len=12_train-percent=0.8_log_val.pkl',\n",
       " 'perfect-teacher_pedagogical-demos_k=2_train-percent=0.05_log_train.pkl',\n",
       " 'perfect-teacher_pedagogical-demos_k=2_train-percent=0.05_log_val.pkl',\n",
       " 'perfect-teacher_pedagogical-demos_k=2_train-percent=0.8_log_train.pkl',\n",
       " 'perfect-teacher_pedagogical-demos_k=2_train-percent=0.8_log_val.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = os.listdir('qualitative_analysis')\n",
    "file_names.sort()\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d9cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "perfect-teacher_lang_max-message-len=12_train-percent=0.05_log_train.pkl\n",
      "MI 0.0023970843317159796\n",
      "unique reward assignments 28\n",
      "unique signals 2\n",
      "-------\n",
      "Val\n",
      "perfect-teacher_lang_max-message-len=12_train-percent=0.05_log_val.pkl\n",
      "MI 0.029824936985940523\n",
      "unique reward assignments 546\n",
      "unique signals 2\n",
      "-------\n",
      "Train\n",
      "perfect-teacher_lang_max-message-len=12_train-percent=0.8_log_train.pkl\n",
      "MI 0.2082777097664975\n",
      "unique reward assignments 460\n",
      "unique signals 21\n",
      "-------\n",
      "Val\n",
      "perfect-teacher_lang_max-message-len=12_train-percent=0.8_log_val.pkl\n",
      "MI 0.08089293834141445\n",
      "unique reward assignments 116\n",
      "unique signals 18\n",
      "-------\n",
      "Train\n",
      "perfect-teacher_pedagogical-demos_k=2_train-percent=0.05_log_train.pkl\n",
      "MI 0.05752849231753397\n",
      "unique reward assignments 28\n",
      "unique signals 40\n",
      "-------\n",
      "Val\n",
      "perfect-teacher_pedagogical-demos_k=2_train-percent=0.05_log_val.pkl\n",
      "MI 0.45040774041400183\n",
      "unique reward assignments 547\n",
      "unique signals 69\n",
      "-------\n",
      "Train\n",
      "perfect-teacher_pedagogical-demos_k=2_train-percent=0.8_log_train.pkl\n",
      "MI 0.4369496584019755\n",
      "unique reward assignments 460\n",
      "unique signals 74\n",
      "-------\n",
      "Val\n",
      "perfect-teacher_pedagogical-demos_k=2_train-percent=0.8_log_val.pkl\n",
      "MI 0.23907560674424577\n",
      "unique reward assignments 116\n",
      "unique signals 66\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "unique_signals = {}\n",
    "for file_name in file_names:\n",
    "    df = pd.read_pickle(os.path.join('qualitative_analysis', file_name))\n",
    "    #print(df.columns)\n",
    "    reward_assignments = [str(assignment) for assignment in df['reward_assignment'].tolist()]\n",
    "    messages = [str(message) for message in df['signal'].tolist()]\n",
    "    mi = mutual_information(reward_assignments, messages)\n",
    "    if 'train' in file_name[-10:]: print('Train')\n",
    "    else: print('Val')\n",
    "    print(file_name)\n",
    "    print('MI', mi)\n",
    "    print('unique reward assignments', len(set(reward_assignments)))\n",
    "    print('unique signals', len(set(messages)))\n",
    "    print('-------')\n",
    "    \n",
    "    unique_signals[file_name] = set(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0339e61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "69\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "set1 = unique_signals['perfect-teacher_pedagogical-demos_k=2_train-percent=0.05_log_train.pkl']\n",
    "set2 = unique_signals['perfect-teacher_pedagogical-demos_k=2_train-percent=0.05_log_val.pkl']\n",
    "print(len(set1))\n",
    "print(len(set2))\n",
    "print(len(set2) - len(set1.intersection(set2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f43380d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(((-2.0, 6.0, 2.0, -6.0), (3.0, 1.0, -1.0, -3.0)), 8),\n",
       " (((-2.0, 6.0, -6.0, 2.0), (3.0, -1.0, 1.0, -3.0)), 7),\n",
       " (((6.0, -6.0, 2.0, -2.0), (3.0, 1.0, -1.0, -3.0)), 6),\n",
       " (((-2.0, 2.0, -6.0, 6.0), (-3.0, 3.0, -1.0, 1.0)), 6),\n",
       " (((-6.0, 2.0, 6.0, -2.0), (-3.0, 3.0, 1.0, -1.0)), 6),\n",
       " (((-6.0, 2.0, 6.0, -2.0), (-1.0, 3.0, -3.0, 1.0)), 6),\n",
       " (((6.0, 2.0, -2.0, -6.0), (1.0, -3.0, 3.0, -1.0)), 6),\n",
       " (((6.0, -2.0, 2.0, -6.0), (-3.0, 1.0, 3.0, -1.0)), 5),\n",
       " (((-6.0, 6.0, 2.0, -2.0), (3.0, -3.0, 1.0, -1.0)), 5),\n",
       " (((2.0, -6.0, -2.0, 6.0), (-1.0, 3.0, -3.0, 1.0)), 5),\n",
       " (((-2.0, -6.0, 2.0, 6.0), (-1.0, 3.0, 1.0, -3.0)), 5),\n",
       " (((-6.0, 6.0, -2.0, 2.0), (-3.0, 3.0, 1.0, -1.0)), 5),\n",
       " (((-6.0, 2.0, 6.0, -2.0), (-3.0, -1.0, 1.0, 3.0)), 5),\n",
       " (((-2.0, 6.0, -6.0, 2.0), (-1.0, -3.0, 1.0, 3.0)), 5),\n",
       " (((-6.0, 2.0, -2.0, 6.0), (3.0, -1.0, -3.0, 1.0)), 5),\n",
       " (((-2.0, -6.0, 6.0, 2.0), (1.0, 3.0, -3.0, -1.0)), 4),\n",
       " (((2.0, 6.0, -6.0, -2.0), (1.0, 3.0, -3.0, -1.0)), 4),\n",
       " (((6.0, -2.0, -6.0, 2.0), (-1.0, 1.0, 3.0, -3.0)), 4),\n",
       " (((2.0, -2.0, 6.0, -6.0), (3.0, -3.0, 1.0, -1.0)), 4),\n",
       " (((-2.0, -6.0, 2.0, 6.0), (-3.0, 1.0, -1.0, 3.0)), 4)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_diverse_df = pd.read_pickle('qualitative_analysis/perfect-teacher_lang_max-message-len=12_train-percent=0.8_log_val.pkl')\n",
    "arbitrary_message = lang_diverse_df['signal'][0]\n",
    "indices = []\n",
    "for i in range(len(lang_diverse_df)):\n",
    "    if np.array_equal(lang_diverse_df['signal'][i], arbitrary_message):\n",
    "        indices.append(i)\n",
    "\n",
    "reward_assignments_as_tuples = []\n",
    "for reward_assignment in lang_diverse_df['reward_assignment'][indices].tolist():\n",
    "    reward_assignment_as_tuple = tuple([tuple(reward_assignment[0]), tuple(reward_assignment[1])])\n",
    "    reward_assignments_as_tuples.append(reward_assignment_as_tuple)\n",
    "    \n",
    "c = Counter(reward_assignments_as_tuples)\n",
    "c.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e82837a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n",
      "0.1375\n",
      "blue\n",
      "0.2\n",
      "green\n",
      "0.025\n",
      "purple\n",
      "-0.3625\n",
      "circle\n",
      "-0.1125\n",
      "square\n",
      "0.60625\n",
      "triangle\n",
      "-0.23125\n",
      "pentagon\n",
      "-0.2625\n",
      "[0.1375, 0.2, 0.025, -0.3625, -0.1125, 0.60625, -0.23125, -0.2625]\n"
     ]
    }
   ],
   "source": [
    "colors = ['red', 'blue', 'green', 'purple']\n",
    "shapes = ['circle', 'square', 'triangle', 'pentagon']\n",
    "value_counts = {}\n",
    "for color in colors:\n",
    "    value_counts[color] = []\n",
    "for shape in shapes:\n",
    "    value_counts[shape] = []\n",
    "\n",
    "for reward_assignment in lang_diverse_df['reward_assignment'][indices].tolist():\n",
    "    \n",
    "    color_assignment = reward_assignment[0]\n",
    "    shape_assignment = reward_assignment[1]\n",
    "    for i in range(4):\n",
    "        color = colors[i]\n",
    "        reward_associated_with_color = color_assignment[i]\n",
    "        value_counts[color].append(reward_associated_with_color)\n",
    "        \n",
    "        shape = shapes[i]\n",
    "        reward_associated_with_shape = shape_assignment[i]\n",
    "        value_counts[shape].append(reward_associated_with_shape)\n",
    "\n",
    "for name, rewards in value_counts.items():\n",
    "    print(name)\n",
    "    print(np.mean(rewards))\n",
    "    \n",
    "means = []\n",
    "for name, rewards in value_counts.items():\n",
    "    means.append(np.mean(rewards))\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14e0f62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[1.25, 1.125, -0.75, -1.625, -0.0625, 0.0, 0.6875, -0.625]\n",
      "13\n",
      "[-0.125, -0.125, 0.5, -0.25, -0.1875, 0.5, -1.125, 0.8125]\n",
      "35\n",
      "[1.875, 0.5, -0.5, -1.875, 0.25, -0.125, 0.375, -0.5]\n"
     ]
    }
   ],
   "source": [
    "for batch_idx in range(100):\n",
    "    lang_diverse_df = pd.read_pickle('qualitative_analysis/perfect-teacher_lang_max-message-len=12_train-percent=0.8_log_val.pkl')\n",
    "    arbitrary_message = lang_diverse_df['signal'][32*batch_idx]\n",
    "    indices = []\n",
    "    for i in range(len(lang_diverse_df)):\n",
    "        if np.array_equal(lang_diverse_df['signal'][i], arbitrary_message):\n",
    "            indices.append(i)\n",
    "\n",
    "    reward_assignments_as_tuples = []\n",
    "    for reward_assignment in lang_diverse_df['reward_assignment'][indices].tolist():\n",
    "        reward_assignment_as_tuple = tuple([tuple(reward_assignment[0]), tuple(reward_assignment[1])])\n",
    "        reward_assignments_as_tuples.append(reward_assignment_as_tuple)\n",
    "\n",
    "    c = Counter(reward_assignments_as_tuples)\n",
    "    \n",
    "    colors = ['red', 'blue', 'green', 'purple']\n",
    "    shapes = ['circle', 'square', 'triangle', 'pentagon']\n",
    "    value_counts = {}\n",
    "    for color in colors:\n",
    "        value_counts[color] = []\n",
    "    for shape in shapes:\n",
    "        value_counts[shape] = []\n",
    "        \n",
    "    for reward_assignment in lang_diverse_df['reward_assignment'][indices].tolist():\n",
    "    \n",
    "        color_assignment = reward_assignment[0]\n",
    "        shape_assignment = reward_assignment[1]\n",
    "        for i in range(4):\n",
    "            color = colors[i]\n",
    "            reward_associated_with_color = color_assignment[i]\n",
    "            value_counts[color].append(reward_associated_with_color)\n",
    "\n",
    "            shape = shapes[i]\n",
    "            reward_associated_with_shape = shape_assignment[i]\n",
    "            value_counts[shape].append(reward_associated_with_shape)\n",
    "\n",
    "    #print(value_counts)\n",
    "    means = []\n",
    "    for name, rewards in value_counts.items():\n",
    "        #print(name)\n",
    "        means.append(np.mean(rewards))\n",
    "    #print(means[6])\n",
    "    if means[5] < means[7] or means[5] < means[6] or means[5] < means[4]:\n",
    "        print(batch_idx)\n",
    "        print(means)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ff689db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n",
      "0.4650735294117647\n",
      "blue\n",
      "-0.2959558823529412\n",
      "green\n",
      "0.14613970588235295\n",
      "purple\n",
      "-0.31525735294117646\n",
      "circle\n",
      "-0.19623161764705882\n",
      "square\n",
      "0.48483455882352944\n",
      "triangle\n",
      "-0.1213235294117647\n",
      "pentagon\n",
      "-0.16727941176470587\n"
     ]
    }
   ],
   "source": [
    "for reward_assignment in lang_diverse_df['reward_assignment'][indices].tolist():\n",
    "    \n",
    "    color_assignment = reward_assignment[0]\n",
    "    shape_assignment = reward_assignment[1]\n",
    "    for i in range(4):\n",
    "        color = colors[i]\n",
    "        reward_associated_with_color = color_assignment[i]\n",
    "        value_counts[color].append(reward_associated_with_color)\n",
    "        \n",
    "        shape = shapes[i]\n",
    "        reward_associated_with_shape = shape_assignment[i]\n",
    "        value_counts[shape].append(reward_associated_with_shape)\n",
    "\n",
    "for name, rewards in value_counts.items():\n",
    "    print(name)\n",
    "    print(np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d97b7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4875  , -0.11375 ,  0.0275  , -0.40125 , -0.14375 ,  0.408125,\n",
       "       -0.0675  , -0.196875])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_flattened = []\n",
    "for i in range(len(lang_diverse_df)):\n",
    "    flattened_array = lang_diverse_df['reward_assignment'][i].reshape(8,)\n",
    "    all_flattened.append(flattened_array)\n",
    "    \n",
    "np.mean(np.array(all_flattened), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d2cd723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perfect-teacher_lang_max-message-len=12_train-percent=0.05_log_train.pkl\n",
      "[-1.81375   0.14625   1.87875  -0.21125   0.22     -0.406875  0.234375\n",
      " -0.0475  ]\n",
      "perfect-teacher_lang_max-message-len=12_train-percent=0.05_log_val.pkl\n",
      "[ 0.1575  -0.1175   0.0175  -0.0575  -0.01875  0.01875  0.00625 -0.00625]\n",
      "perfect-teacher_lang_max-message-len=12_train-percent=0.8_log_train.pkl\n",
      "[-0.12125  -0.01875   0.04375   0.09625   0.0775   -0.038125 -0.01375\n",
      " -0.025625]\n",
      "perfect-teacher_lang_max-message-len=12_train-percent=0.8_log_val.pkl\n",
      "[ 0.4875   -0.11375   0.0275   -0.40125  -0.14375   0.408125 -0.0675\n",
      " -0.196875]\n",
      "perfect-teacher_pedagogical-demos_k=2_train-percent=0.05_log_train.pkl\n",
      "[-0.32625  -1.10125   1.21375   0.21375  -0.061875 -0.440625 -0.15625\n",
      "  0.65875 ]\n",
      "perfect-teacher_pedagogical-demos_k=2_train-percent=0.05_log_val.pkl\n",
      "[ 0.01125   0.10875  -0.14625   0.02625  -0.04875   0.05625  -0.044375\n",
      "  0.036875]\n",
      "perfect-teacher_pedagogical-demos_k=2_train-percent=0.8_log_train.pkl\n",
      "[-0.1325   -0.235     0.195     0.1725   -0.040625  0.02875   0.005\n",
      "  0.006875]\n",
      "perfect-teacher_pedagogical-demos_k=2_train-percent=0.8_log_val.pkl\n",
      "[ 0.5525    0.6375   -0.4675   -0.7225    0.040625 -0.135     0.003125\n",
      "  0.09125 ]\n"
     ]
    }
   ],
   "source": [
    "for file_name in file_names:\n",
    "    df = pd.read_pickle(os.path.join('qualitative_analysis', file_name))\n",
    "    all_flattened = []\n",
    "    for i in range(len(df)):\n",
    "        flattened_array = df['reward_assignment'][i].reshape(8,)\n",
    "        all_flattened.append(flattened_array)\n",
    "\n",
    "    print(file_name)\n",
    "    print(np.mean(np.array(all_flattened), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82df876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
