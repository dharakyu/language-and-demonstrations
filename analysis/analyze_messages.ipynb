{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_ROOT = '/home/dharakyu/signaling-bandits/outputs/' \\\n",
    "                '4x4-partial_chunk-2_chain-len-3_run-4_val'\n",
    "NUM_SHAPES = 4\n",
    "NUM_COLORS = 4\n",
    "\n",
    "df = pd.read_pickle(FILE_PATH_ROOT + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get labels (utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_col_to_np_array(df, col_name):\n",
    "    \"\"\"\n",
    "    Helper function to convert a column of a df to a np array\n",
    "    \"\"\"\n",
    "    list_of_np_arrays = df[col_name].tolist()\n",
    "    return np.concatenate(list_of_np_arrays, axis=0)\n",
    "\n",
    "def extract_utilities_from_reward_matrix(stack):\n",
    "    \"\"\"\n",
    "    Extract the utilities from the reward matrices\n",
    "    \"\"\"\n",
    "    all_utilities = []\n",
    "    for i in range(3200):\n",
    "        row = stack[i, :]\n",
    "        matrix = row.reshape(NUM_COLORS * NUM_SHAPES, -1)\n",
    "        utilities = matrix[:, -2]\n",
    "        all_utilities.append(utilities)\n",
    "    return np.array(all_utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_matrices = convert_df_col_to_np_array(df=df, col_name='reward_matrix') # (3200, NUM_COLORS*NUM_SHAPES*encoding_len)\n",
    "utilities = extract_utilities_from_reward_matrix(reward_matrices) # (3200, NUM_COLORS*NUM_SHAPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get inputs (messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['message_0', 'message_1', 'message_2']\n"
     ]
    }
   ],
   "source": [
    "message_col_names = [col_name for col_name in df.columns.tolist() if 'message' in col_name]\n",
    "print(message_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 3, 320)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [convert_df_col_to_np_array(df=df, col_name=col_name) for col_name in message_col_names]\n",
    "messages = np.array(messages)\n",
    "messages = np.swapaxes(messages, 0, 1)\n",
    "messages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSE(messages, utilities):\n",
    "    num_agents = messages.shape[1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(messages, utilities)\n",
    "    \n",
    "    avg_mse_for_each_gen = []\n",
    "    \n",
    "    # for each generation of agents\n",
    "    for gen in range(num_agents):\n",
    "        #print('gen', gen)\n",
    "        X_train_gen = X_train[:, gen, :]\n",
    "        X_test_gen = X_test[:, gen, :]\n",
    "\n",
    "        mses = []\n",
    "        # for each object in the reward matrix\n",
    "        for util_idx in range(y_train.shape[1]):\n",
    "            clf = Ridge().fit(X_train_gen, y_train[:, util_idx])\n",
    "            pred = clf.predict(X_test_gen)\n",
    "            mse = clf.score(X_test_gen, y_test[:, util_idx])\n",
    "            mses.append(mse)\n",
    "\n",
    "        avg_mse_for_each_gen.append(np.mean(mses))\n",
    "    return avg_mse_for_each_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14474431121798054, 0.2022763465206406, 0.22453003194925117]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_mse = get_MSE(messages, utilities)\n",
    "avg_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it in a loop, for different experimental conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chain length 2\n",
      "MSE at gen 0 0.15249019839231806\n",
      "MSE at gen 1 0.16559920683749427\n",
      "chain length 3\n",
      "MSE at gen 0 0.1452243277945769\n",
      "MSE at gen 1 0.18950288822335631\n",
      "MSE at gen 2 0.2075798799606381\n",
      "chain length 4\n",
      "MSE at gen 0 0.16559906718085596\n",
      "MSE at gen 1 0.22155681617148565\n",
      "MSE at gen 2 0.24968189732755103\n",
      "MSE at gen 3 0.25265211834531726\n",
      "chain length 5\n",
      "MSE at gen 0 0.14880802541477228\n",
      "MSE at gen 1 0.1987770888243959\n",
      "MSE at gen 2 0.22459151125821125\n",
      "MSE at gen 3 0.2333077561668032\n",
      "MSE at gen 4 0.23597813272698157\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH_ROOT = '/home/dharakyu/signaling-bandits/outputs/' \\\n",
    "                '4x4-partial_chunk-2_chain-len-'\n",
    "chain_lens = [2, 3, 4, 5]\n",
    "run_nums = [1, 2, 3, 4, 5]\n",
    "\n",
    "for chain_len in chain_lens:\n",
    "    print('chain length', chain_len)\n",
    "    mse_for_each_gen = []\n",
    "    for run_num in run_nums:\n",
    "        if chain_len == 2 and run_num >= 4: continue\n",
    "        full_path = FILE_PATH_ROOT + '{chain_len}_run-{run_num}_val.pkl'.format(chain_len=chain_len, run_num=run_num)\n",
    "        df = pd.read_pickle(full_path)\n",
    "        reward_matrices = convert_df_col_to_np_array(df=df, col_name='reward_matrix') # (3200, NUM_COLORS*NUM_SHAPES*encoding_len)\n",
    "        utilities = extract_utilities_from_reward_matrix(reward_matrices) # (3200, NUM_COLORS*NUM_SHAPES)\n",
    "        message_col_names = [col_name for col_name in df.columns.tolist() if 'message' in col_name]\n",
    "        messages = [convert_df_col_to_np_array(df=df, col_name=col_name) for col_name in message_col_names]\n",
    "        messages = np.array(messages)\n",
    "        messages = np.swapaxes(messages, 0, 1)\n",
    "        avg_mse = get_MSE(messages, utilities)\n",
    "        mse_for_each_gen.append(avg_mse)\n",
    "    mse_for_each_gen = np.array(mse_for_each_gen)\n",
    "    gen_means = np.mean(mse_for_each_gen, axis=0)\n",
    "    for i in range(gen_means.shape[0]):\n",
    "        print('MSE at gen', i, gen_means[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative analysis of messages for a single reward matrix\n",
    "\n",
    "The approach: within a single run, find a single reward matrix, and get all the messages associated with it. Show how similar those messages are to one another. Compare across generations - my hypothesis is that the messages should be increasingly similar as generation increases, since there is increasing overlap in what the agents see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in file\n",
    "file_path = '/home/dharakyu/signaling-bandits/outputs/' \\\n",
    "                '4x4-partial_chunk-2_chain-len-5_run-1_val.pkl'\n",
    "NUM_SHAPES = 4\n",
    "NUM_COLORS = 4\n",
    "\n",
    "df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   8,   87,  108, 1025, 1265, 1448, 1493, 1546, 1599, 2010, 2384,\n",
       "       2542, 2804, 3133])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_matrices = convert_df_col_to_np_array(df=df, col_name='reward_matrix') # (3200, NUM_COLORS*NUM_SHAPES*encoding_len)\n",
    "utilities = extract_utilities_from_reward_matrix(reward_matrices) # (3200, NUM_COLORS*NUM_SHAPES)\n",
    "_, indices = np.unique(utilities, return_inverse=True, axis=0)\n",
    "indices.shape\n",
    "# pick the arrangement of utilities that occurs most frequently\n",
    "c = Counter(list(indices))\n",
    "most_freq_val, count = c.most_common(1)[0]\n",
    "\n",
    "# and get the indices where it appears\n",
    "indices_of_most_freq_val = np.where(indices == most_freq_val)[0]\n",
    "indices_of_most_freq_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['message_0', 'message_1', 'message_2', 'message_3', 'message_4']\n",
      "(3200, 5, 320)\n",
      "(14, 5, 320)\n"
     ]
    }
   ],
   "source": [
    "# get the messages corresponding to those indices\n",
    "message_col_names = [col_name for col_name in df.columns.tolist() if 'message' in col_name]\n",
    "print(message_col_names)\n",
    "messages = [convert_df_col_to_np_array(df=df, col_name=col_name) for col_name in message_col_names]\n",
    "messages = np.array(messages)\n",
    "messages = np.swapaxes(messages, 0, 1)\n",
    "print(messages.shape)\n",
    "\n",
    "subset_of_messages = messages[indices_of_most_freq_val]\n",
    "print(subset_of_messages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 0\n",
      "(7, 320)\n",
      "[1 1 2 7 1 1 1]\n",
      "generation 1\n",
      "(2, 320)\n",
      "[ 1 13]\n",
      "generation 2\n",
      "(1, 320)\n",
      "[14]\n",
      "generation 3\n",
      "(1, 320)\n",
      "[14]\n",
      "generation 4\n",
      "(1, 320)\n",
      "[14]\n"
     ]
    }
   ],
   "source": [
    "# start by counting how many of the messages are the same\n",
    "for i in range(5):\n",
    "    print('generation', i)\n",
    "    unique_messages, counts = np.unique(subset_of_messages[:, i, :], return_counts=True, axis=0)\n",
    "    print(unique_messages.shape)\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 320)\n",
      "47\n",
      "(3200, 320)\n",
      "34\n",
      "(3200, 320)\n",
      "30\n",
      "(3200, 320)\n",
      "22\n",
      "(3200, 320)\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(messages[:, i, :].shape)\n",
    "    unique_messages_across_iteration = np.unique(messages[:, i, :], axis=0)\n",
    "    print(len(unique_messages_across_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
